{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehahs03/medical-image-analysis/blob/main/resnet1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnIVnB6T-tqh",
        "outputId": "edeb7730-8d98-4742-e117-346f2a5536f0"
      },
      "source": [
        "!git clone https://github.com/snehahs03/medical-image-analysis.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'medical-image-analysis'...\n",
            "remote: Enumerating objects: 3785, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 3785 (delta 9), reused 0 (delta 0), pack-reused 3763\u001b[K\n",
            "Receiving objects: 100% (3785/3785), 336.97 MiB | 37.29 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "Checking out files: 100% (3887/3887), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb19RMs1-_cu"
      },
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tensorflow.keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D \n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.preprocessing import image\n",
        "from glob import glob"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2YXrT4J_Mer"
      },
      "source": [
        "def Dataset_loader(DIR, RESIZE, sigmaX=10):\n",
        "    IMG = []\n",
        "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "    for IMAGE_NAME in tqdm(os.listdir(DIR)):\n",
        "        PATH = os.path.join(DIR,IMAGE_NAME)\n",
        "        _, ftype = os.path.splitext(PATH)\n",
        "        if ftype == \".jpg\":\n",
        "            img = read(PATH)\n",
        "           \n",
        "            img = cv2.resize(img, (RESIZE,RESIZE))\n",
        "           \n",
        "            IMG.append(np.array(img))\n",
        "    return IMG"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAoAK-7l_ULL",
        "outputId": "ea0fce94-d2d5-4b92-82ad-3deac1f08ecd"
      },
      "source": [
        "eczema_train = np.array(Dataset_loader(\"/content/medical-image-analysis/train/Eczema Photos\", 224))\n",
        "melanoma_train = np.array(Dataset_loader(\"/content/medical-image-analysis/train/Melanoma Skin Cancer Nevi and Moles\",224))\n",
        "psoriasis_train = np.array(Dataset_loader(\"/content/medical-image-analysis/train/Psoriasis pictures Lichen Planus and related diseases\",224))\n",
        "eczema_test = np.array(Dataset_loader(\"/content/medical-image-analysis/test/Eczema Photos\",224))\n",
        "melonoma_test = np.array(Dataset_loader(\"/content/medical-image-analysis/test/Melanoma Skin Cancer Nevi and Moles\",224))\n",
        "psoriasis_test = np.array(Dataset_loader(\"/content/medical-image-analysis/test/Psoriasis pictures Lichen Planus and related diseases\", 224))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1235/1235 [00:08<00:00, 152.55it/s]\n",
            "100%|██████████| 463/463 [00:03<00:00, 149.60it/s]\n",
            "100%|██████████| 1405/1405 [00:09<00:00, 153.49it/s]\n",
            "100%|██████████| 309/309 [00:01<00:00, 156.88it/s]\n",
            "100%|██████████| 116/116 [00:00<00:00, 153.31it/s]\n",
            "100%|██████████| 352/352 [00:02<00:00, 155.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOFq80Gi_XID"
      },
      "source": [
        "#labelling \n",
        "eczema_train_label = np.full(len(eczema_train),0)\n",
        "melonoma_train_label = np.full(len(melanoma_train),1)\n",
        "psoriasis_train_label = np.full(len(psoriasis_train),2)\n",
        "eczema_test_label = np.full(len(eczema_test),0)\n",
        "melonoma_test_label = np.full(len(melonoma_test),1)\n",
        "psoriasis_test_label = np.full(len(psoriasis_test),2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuibS0Ab_lTC",
        "outputId": "54085f50-c345-4987-8374-e203044591cb"
      },
      "source": [
        "X_train = np.concatenate((eczema_train, melanoma_train, psoriasis_train), axis=0)\n",
        "Y_train = np.concatenate((eczema_train_label, melonoma_train_label, psoriasis_train_label), axis=0)\n",
        "X_test = np.concatenate((eczema_test, melonoma_test, psoriasis_test), axis=0)\n",
        "Y_test = np.concatenate((eczema_test_label, melonoma_test_label, psoriasis_test_label), axis = 0)\n",
        "print(Y_test.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(777,)\n",
            "(777, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q46ALqdo_oS8"
      },
      "source": [
        "s = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_train = X_train[s]\n",
        "Y_train = Y_train[s]\n",
        "\n",
        "s = np.arange(X_test.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_test = X_test[s]\n",
        "Y_test = Y_test[s]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02lI6ES2_rGK"
      },
      "source": [
        "Y_train = to_categorical(Y_train, num_classes= 3)\n",
        "Y_test = to_categorical(Y_test, num_classes= 3)\n",
        "\n",
        "#train and evaluation split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "    X_train, Y_train, \n",
        "    test_size=0.3, \n",
        "    random_state=5\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lICf_EbY_uCj",
        "outputId": "421c17f4-7d36-431d-d2ba-22fd5df3e7f6"
      },
      "source": [
        "X_train.shape, Y_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2172, 224, 224, 3), (2172, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIsOJ0JI_wQL",
        "outputId": "5e7d4776-116b-4a99-98de-ede22c0b220d"
      },
      "source": [
        "X_val.shape, Y_val.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((931, 224, 224, 3), (931, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DE753QA_yXT",
        "outputId": "af21e147-4fec-4978-cd0c-c535151ac012"
      },
      "source": [
        "X_test.shape, Y_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((777, 224, 224, 3), (777, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LI5XNMrgVHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d46f004-b669-44d4-85ef-d06b390ce9de"
      },
      "source": [
        "pre_trained_model = tensorflow.keras.applications.ResNet50(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2LZWem8gAef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32521158-11c9-44e4-96ae-cfb9d0b922e1"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "    print(layer.name)\n",
        "    if hasattr(layer, 'moving_mean') and hasattr(layer, 'moving_variance'):\n",
        "        layer.trainable = True\n",
        "        K.eval(K.update(layer.moving_mean, K.zeros_like(layer.moving_mean)))\n",
        "        K.eval(K.update(layer.moving_variance, K.zeros_like(layer.moving_variance)))\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "print(len(pre_trained_model.layers))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_1\n",
            "conv1_pad\n",
            "conv1_conv\n",
            "conv1_bn\n",
            "conv1_relu\n",
            "pool1_pad\n",
            "pool1_pool\n",
            "conv2_block1_1_conv\n",
            "conv2_block1_1_bn\n",
            "conv2_block1_1_relu\n",
            "conv2_block1_2_conv\n",
            "conv2_block1_2_bn\n",
            "conv2_block1_2_relu\n",
            "conv2_block1_0_conv\n",
            "conv2_block1_3_conv\n",
            "conv2_block1_0_bn\n",
            "conv2_block1_3_bn\n",
            "conv2_block1_add\n",
            "conv2_block1_out\n",
            "conv2_block2_1_conv\n",
            "conv2_block2_1_bn\n",
            "conv2_block2_1_relu\n",
            "conv2_block2_2_conv\n",
            "conv2_block2_2_bn\n",
            "conv2_block2_2_relu\n",
            "conv2_block2_3_conv\n",
            "conv2_block2_3_bn\n",
            "conv2_block2_add\n",
            "conv2_block2_out\n",
            "conv2_block3_1_conv\n",
            "conv2_block3_1_bn\n",
            "conv2_block3_1_relu\n",
            "conv2_block3_2_conv\n",
            "conv2_block3_2_bn\n",
            "conv2_block3_2_relu\n",
            "conv2_block3_3_conv\n",
            "conv2_block3_3_bn\n",
            "conv2_block3_add\n",
            "conv2_block3_out\n",
            "conv3_block1_1_conv\n",
            "conv3_block1_1_bn\n",
            "conv3_block1_1_relu\n",
            "conv3_block1_2_conv\n",
            "conv3_block1_2_bn\n",
            "conv3_block1_2_relu\n",
            "conv3_block1_0_conv\n",
            "conv3_block1_3_conv\n",
            "conv3_block1_0_bn\n",
            "conv3_block1_3_bn\n",
            "conv3_block1_add\n",
            "conv3_block1_out\n",
            "conv3_block2_1_conv\n",
            "conv3_block2_1_bn\n",
            "conv3_block2_1_relu\n",
            "conv3_block2_2_conv\n",
            "conv3_block2_2_bn\n",
            "conv3_block2_2_relu\n",
            "conv3_block2_3_conv\n",
            "conv3_block2_3_bn\n",
            "conv3_block2_add\n",
            "conv3_block2_out\n",
            "conv3_block3_1_conv\n",
            "conv3_block3_1_bn\n",
            "conv3_block3_1_relu\n",
            "conv3_block3_2_conv\n",
            "conv3_block3_2_bn\n",
            "conv3_block3_2_relu\n",
            "conv3_block3_3_conv\n",
            "conv3_block3_3_bn\n",
            "conv3_block3_add\n",
            "conv3_block3_out\n",
            "conv3_block4_1_conv\n",
            "conv3_block4_1_bn\n",
            "conv3_block4_1_relu\n",
            "conv3_block4_2_conv\n",
            "conv3_block4_2_bn\n",
            "conv3_block4_2_relu\n",
            "conv3_block4_3_conv\n",
            "conv3_block4_3_bn\n",
            "conv3_block4_add\n",
            "conv3_block4_out\n",
            "conv4_block1_1_conv\n",
            "conv4_block1_1_bn\n",
            "conv4_block1_1_relu\n",
            "conv4_block1_2_conv\n",
            "conv4_block1_2_bn\n",
            "conv4_block1_2_relu\n",
            "conv4_block1_0_conv\n",
            "conv4_block1_3_conv\n",
            "conv4_block1_0_bn\n",
            "conv4_block1_3_bn\n",
            "conv4_block1_add\n",
            "conv4_block1_out\n",
            "conv4_block2_1_conv\n",
            "conv4_block2_1_bn\n",
            "conv4_block2_1_relu\n",
            "conv4_block2_2_conv\n",
            "conv4_block2_2_bn\n",
            "conv4_block2_2_relu\n",
            "conv4_block2_3_conv\n",
            "conv4_block2_3_bn\n",
            "conv4_block2_add\n",
            "conv4_block2_out\n",
            "conv4_block3_1_conv\n",
            "conv4_block3_1_bn\n",
            "conv4_block3_1_relu\n",
            "conv4_block3_2_conv\n",
            "conv4_block3_2_bn\n",
            "conv4_block3_2_relu\n",
            "conv4_block3_3_conv\n",
            "conv4_block3_3_bn\n",
            "conv4_block3_add\n",
            "conv4_block3_out\n",
            "conv4_block4_1_conv\n",
            "conv4_block4_1_bn\n",
            "conv4_block4_1_relu\n",
            "conv4_block4_2_conv\n",
            "conv4_block4_2_bn\n",
            "conv4_block4_2_relu\n",
            "conv4_block4_3_conv\n",
            "conv4_block4_3_bn\n",
            "conv4_block4_add\n",
            "conv4_block4_out\n",
            "conv4_block5_1_conv\n",
            "conv4_block5_1_bn\n",
            "conv4_block5_1_relu\n",
            "conv4_block5_2_conv\n",
            "conv4_block5_2_bn\n",
            "conv4_block5_2_relu\n",
            "conv4_block5_3_conv\n",
            "conv4_block5_3_bn\n",
            "conv4_block5_add\n",
            "conv4_block5_out\n",
            "conv4_block6_1_conv\n",
            "conv4_block6_1_bn\n",
            "conv4_block6_1_relu\n",
            "conv4_block6_2_conv\n",
            "conv4_block6_2_bn\n",
            "conv4_block6_2_relu\n",
            "conv4_block6_3_conv\n",
            "conv4_block6_3_bn\n",
            "conv4_block6_add\n",
            "conv4_block6_out\n",
            "conv5_block1_1_conv\n",
            "conv5_block1_1_bn\n",
            "conv5_block1_1_relu\n",
            "conv5_block1_2_conv\n",
            "conv5_block1_2_bn\n",
            "conv5_block1_2_relu\n",
            "conv5_block1_0_conv\n",
            "conv5_block1_3_conv\n",
            "conv5_block1_0_bn\n",
            "conv5_block1_3_bn\n",
            "conv5_block1_add\n",
            "conv5_block1_out\n",
            "conv5_block2_1_conv\n",
            "conv5_block2_1_bn\n",
            "conv5_block2_1_relu\n",
            "conv5_block2_2_conv\n",
            "conv5_block2_2_bn\n",
            "conv5_block2_2_relu\n",
            "conv5_block2_3_conv\n",
            "conv5_block2_3_bn\n",
            "conv5_block2_add\n",
            "conv5_block2_out\n",
            "conv5_block3_1_conv\n",
            "conv5_block3_1_bn\n",
            "conv5_block3_1_relu\n",
            "conv5_block3_2_conv\n",
            "conv5_block3_2_bn\n",
            "conv5_block3_2_relu\n",
            "conv5_block3_3_conv\n",
            "conv5_block3_3_bn\n",
            "conv5_block3_add\n",
            "conv5_block3_out\n",
            "175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arThh6CiALfL",
        "outputId": "67efa36f-a91b-4cca-ebc4-5cdf8feea1f0"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('conv5_block3_out')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23NNU55ehETQ"
      },
      "source": [
        "x = tensorflow.keras.layers.Flatten()(last_output)\n",
        "x = tensorflow.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tensorflow.keras.layers.Dropout(0.5)(x)\n",
        "x = tensorflow.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tensorflow.keras.layers.Dropout(0.5)(x)\n",
        "x = tensorflow.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "#Config and compile model\n",
        "\n",
        "model1 = Model(pre_trained_model.input, x)\n",
        "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyILdlHjAj_k"
      },
      "source": [
        "TRAINING "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX5zYiIaAmOL"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=60, width_shift_range=0.2, height_shift_range=0.2,\n",
        "                                   shear_range=0.2, zoom_range=0.2, fill_mode='nearest')\n",
        "\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_datagen.fit(X_val)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0HfvRrmEy_8",
        "outputId": "2056065f-bebb-4cb3-983b-4fce4c1d0289"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 25\n",
        "history0 = model1.fit_generator(train_datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, Y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size), \n",
        "                              validation_steps=(X_val.shape[0] // batch_size))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "33/33 [==============================] - 67s 928ms/step - loss: 2.0488 - accuracy: 0.4768 - val_loss: 183330928.0000 - val_accuracy: 0.4799\n",
            "Epoch 2/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 1.0594 - accuracy: 0.5607 - val_loss: 891.2230 - val_accuracy: 0.4509\n",
            "Epoch 3/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.9382 - accuracy: 0.5745 - val_loss: 4.5475 - val_accuracy: 0.3683\n",
            "Epoch 4/25\n",
            "33/33 [==============================] - 28s 834ms/step - loss: 0.9029 - accuracy: 0.5769 - val_loss: 1.1117 - val_accuracy: 0.4509\n",
            "Epoch 5/25\n",
            "33/33 [==============================] - 28s 837ms/step - loss: 0.8679 - accuracy: 0.6044 - val_loss: 0.9485 - val_accuracy: 0.5737\n",
            "Epoch 6/25\n",
            "33/33 [==============================] - 28s 837ms/step - loss: 0.8545 - accuracy: 0.5911 - val_loss: 0.8648 - val_accuracy: 0.6272\n",
            "Epoch 7/25\n",
            "33/33 [==============================] - 28s 844ms/step - loss: 0.8338 - accuracy: 0.5949 - val_loss: 0.7808 - val_accuracy: 0.6295\n",
            "Epoch 8/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.8255 - accuracy: 0.6120 - val_loss: 0.8155 - val_accuracy: 0.6429\n",
            "Epoch 9/25\n",
            "33/33 [==============================] - 28s 836ms/step - loss: 0.8154 - accuracy: 0.6262 - val_loss: 0.7766 - val_accuracy: 0.6585\n",
            "Epoch 10/25\n",
            "33/33 [==============================] - 28s 841ms/step - loss: 0.7853 - accuracy: 0.6499 - val_loss: 0.7304 - val_accuracy: 0.6853\n",
            "Epoch 11/25\n",
            "33/33 [==============================] - 28s 839ms/step - loss: 0.7721 - accuracy: 0.6471 - val_loss: 0.7674 - val_accuracy: 0.6429\n",
            "Epoch 12/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.7535 - accuracy: 0.6779 - val_loss: 0.7391 - val_accuracy: 0.6719\n",
            "Epoch 13/25\n",
            "33/33 [==============================] - 28s 844ms/step - loss: 0.7341 - accuracy: 0.6670 - val_loss: 0.6897 - val_accuracy: 0.6987\n",
            "Epoch 14/25\n",
            "33/33 [==============================] - 28s 841ms/step - loss: 0.7555 - accuracy: 0.6622 - val_loss: 0.6867 - val_accuracy: 0.6763\n",
            "Epoch 15/25\n",
            "33/33 [==============================] - 28s 838ms/step - loss: 0.7598 - accuracy: 0.6499 - val_loss: 0.7422 - val_accuracy: 0.6540\n",
            "Epoch 16/25\n",
            "33/33 [==============================] - 28s 846ms/step - loss: 0.7164 - accuracy: 0.6698 - val_loss: 0.6772 - val_accuracy: 0.7076\n",
            "Epoch 17/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.6744 - accuracy: 0.6940 - val_loss: 0.6907 - val_accuracy: 0.6942\n",
            "Epoch 18/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.7046 - accuracy: 0.6921 - val_loss: 0.6865 - val_accuracy: 0.6920\n",
            "Epoch 19/25\n",
            "33/33 [==============================] - 28s 837ms/step - loss: 0.6805 - accuracy: 0.6992 - val_loss: 0.6618 - val_accuracy: 0.6853\n",
            "Epoch 20/25\n",
            "33/33 [==============================] - 28s 838ms/step - loss: 0.6850 - accuracy: 0.6869 - val_loss: 0.6646 - val_accuracy: 0.6897\n",
            "Epoch 21/25\n",
            "33/33 [==============================] - 28s 844ms/step - loss: 0.6444 - accuracy: 0.7016 - val_loss: 0.6768 - val_accuracy: 0.7388\n",
            "Epoch 22/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.6646 - accuracy: 0.7021 - val_loss: 0.6632 - val_accuracy: 0.6897\n",
            "Epoch 23/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.6541 - accuracy: 0.7144 - val_loss: 0.6423 - val_accuracy: 0.7388\n",
            "Epoch 24/25\n",
            "33/33 [==============================] - 28s 839ms/step - loss: 0.6247 - accuracy: 0.7239 - val_loss: 0.6921 - val_accuracy: 0.7054\n",
            "Epoch 25/25\n",
            "33/33 [==============================] - 28s 847ms/step - loss: 0.6211 - accuracy: 0.7239 - val_loss: 0.6357 - val_accuracy: 0.7098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFo-3ZAikWt9",
        "outputId": "ed5e7dd4-a056-4cf7-8430-b47364526414"
      },
      "source": [
        "model1.save(\"0thModel.h5\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwKQytXZpVoQ"
      },
      "source": [
        "**FINE TUNING - 1\n",
        "training first 5 layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTmmbBoxnGNg"
      },
      "source": [
        "for layer in pre_trained_model.layers[0:6]:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FXRdFeNnVfA",
        "outputId": "92015998-ab20-435d-dc90-35066f2ae6fe"
      },
      "source": [
        "model2 = Model(pre_trained_model.input, x)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBrdwZ_7nZ0Y"
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, \n",
        "                                            min_lr=0.000001, cooldown=2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1v1RoX6nhuM",
        "outputId": "d591895e-fe13-4887-e401-4b7bd33c77c9"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 25\n",
        "history1 = model2.fit_generator(train_datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, Y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              validation_steps=(X_val.shape[0] // batch_size),\n",
        "                              callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "33/33 [==============================] - 33s 889ms/step - loss: 0.6673 - acc: 0.7315 - val_loss: 0.7215 - val_acc: 0.6897\n",
            "Epoch 2/25\n",
            "33/33 [==============================] - 28s 842ms/step - loss: 0.6563 - acc: 0.7168 - val_loss: 0.7079 - val_acc: 0.6853\n",
            "Epoch 3/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.6067 - acc: 0.7306 - val_loss: 0.7397 - val_acc: 0.6763\n",
            "Epoch 4/25\n",
            "33/33 [==============================] - 28s 847ms/step - loss: 0.6670 - acc: 0.7116 - val_loss: 0.6566 - val_acc: 0.7188\n",
            "Epoch 5/25\n",
            "33/33 [==============================] - 28s 845ms/step - loss: 0.6555 - acc: 0.7130 - val_loss: 0.7331 - val_acc: 0.6719\n",
            "Epoch 6/25\n",
            "33/33 [==============================] - 28s 842ms/step - loss: 0.6197 - acc: 0.7339 - val_loss: 0.6296 - val_acc: 0.7143\n",
            "Epoch 7/25\n",
            "33/33 [==============================] - 28s 844ms/step - loss: 0.6052 - acc: 0.7491 - val_loss: 0.7050 - val_acc: 0.7031\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "Epoch 8/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.5448 - acc: 0.7533 - val_loss: 0.6446 - val_acc: 0.7478\n",
            "Epoch 9/25\n",
            "33/33 [==============================] - 28s 838ms/step - loss: 0.5545 - acc: 0.7571 - val_loss: 0.7292 - val_acc: 0.7031\n",
            "Epoch 10/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.5591 - acc: 0.7609 - val_loss: 0.6112 - val_acc: 0.7366\n",
            "Epoch 11/25\n",
            "33/33 [==============================] - 28s 839ms/step - loss: 0.5212 - acc: 0.7761 - val_loss: 0.6445 - val_acc: 0.7344\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "Epoch 12/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.5193 - acc: 0.7785 - val_loss: 0.5875 - val_acc: 0.7455\n",
            "Epoch 13/25\n",
            "33/33 [==============================] - 28s 835ms/step - loss: 0.5098 - acc: 0.7823 - val_loss: 0.6705 - val_acc: 0.7121\n",
            "Epoch 14/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.5053 - acc: 0.7917 - val_loss: 0.6922 - val_acc: 0.7165\n",
            "Epoch 15/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.5019 - acc: 0.7794 - val_loss: 0.5644 - val_acc: 0.7522\n",
            "Epoch 16/25\n",
            "33/33 [==============================] - 28s 838ms/step - loss: 0.4855 - acc: 0.7894 - val_loss: 0.6129 - val_acc: 0.7210\n",
            "Epoch 17/25\n",
            "33/33 [==============================] - 28s 835ms/step - loss: 0.5087 - acc: 0.7799 - val_loss: 0.6626 - val_acc: 0.7344\n",
            "Epoch 18/25\n",
            "33/33 [==============================] - 28s 838ms/step - loss: 0.5158 - acc: 0.7851 - val_loss: 0.5897 - val_acc: 0.7656\n",
            "Epoch 19/25\n",
            "33/33 [==============================] - 28s 835ms/step - loss: 0.4845 - acc: 0.7927 - val_loss: 0.6521 - val_acc: 0.7232\n",
            "Epoch 20/25\n",
            "33/33 [==============================] - 28s 838ms/step - loss: 0.4997 - acc: 0.7880 - val_loss: 0.7118 - val_acc: 0.7254\n",
            "Epoch 21/25\n",
            "33/33 [==============================] - 28s 836ms/step - loss: 0.4581 - acc: 0.8065 - val_loss: 0.6913 - val_acc: 0.7254\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "Epoch 22/25\n",
            "33/33 [==============================] - 28s 839ms/step - loss: 0.4931 - acc: 0.8027 - val_loss: 0.6892 - val_acc: 0.7232\n",
            "Epoch 23/25\n",
            "33/33 [==============================] - 28s 839ms/step - loss: 0.4767 - acc: 0.8050 - val_loss: 0.6039 - val_acc: 0.7701\n",
            "Epoch 24/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.4595 - acc: 0.7965 - val_loss: 0.6487 - val_acc: 0.7299\n",
            "Epoch 25/25\n",
            "33/33 [==============================] - 28s 838ms/step - loss: 0.4679 - acc: 0.7913 - val_loss: 0.6295 - val_acc: 0.7299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfkewlEdlPGq",
        "outputId": "909c2521-ba3a-4284-c0fd-9a09314b8dc0"
      },
      "source": [
        "model2.save(\"1stModel.h5\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HQpMwG8PouD"
      },
      "source": [
        "**FINE TUNING- 2\n",
        "10 LAYERS TRAINABLE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydKxFAzlPoEE",
        "outputId": "be145ad3-a294-45ee-8a49-add3390a6fef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for layer in pre_trained_model.layers[0:11]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "model3 = Model(pre_trained_model.input, x)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, \n",
        "                                            min_lr=0.000001, cooldown=2)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 25\n",
        "history2 = model3.fit_generator(train_datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, Y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              validation_steps=(X_val.shape[0] // batch_size),\n",
        "                              callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "33/33 [==============================] - 33s 873ms/step - loss: 0.5638 - acc: 0.7832 - val_loss: 0.7499 - val_acc: 0.7188\n",
            "Epoch 2/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.5744 - acc: 0.7709 - val_loss: 0.6660 - val_acc: 0.7188\n",
            "Epoch 3/25\n",
            "33/33 [==============================] - 28s 852ms/step - loss: 0.5275 - acc: 0.7823 - val_loss: 0.7262 - val_acc: 0.7143\n",
            "Epoch 4/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.5509 - acc: 0.7671 - val_loss: 0.6682 - val_acc: 0.7567\n",
            "Epoch 5/25\n",
            "33/33 [==============================] - 28s 844ms/step - loss: 0.5320 - acc: 0.7756 - val_loss: 0.7381 - val_acc: 0.7321\n",
            "Epoch 6/25\n",
            "33/33 [==============================] - 28s 842ms/step - loss: 0.5356 - acc: 0.7756 - val_loss: 0.6561 - val_acc: 0.7299\n",
            "Epoch 7/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.5105 - acc: 0.7984 - val_loss: 0.6800 - val_acc: 0.6875\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "Epoch 8/25\n",
            "33/33 [==============================] - 28s 845ms/step - loss: 0.4826 - acc: 0.7984 - val_loss: 0.6876 - val_acc: 0.7121\n",
            "Epoch 9/25\n",
            "33/33 [==============================] - 28s 841ms/step - loss: 0.4876 - acc: 0.7965 - val_loss: 0.6221 - val_acc: 0.7656\n",
            "Epoch 10/25\n",
            "33/33 [==============================] - 28s 840ms/step - loss: 0.4570 - acc: 0.8022 - val_loss: 0.6944 - val_acc: 0.7344\n",
            "Epoch 11/25\n",
            "33/33 [==============================] - 28s 846ms/step - loss: 0.4526 - acc: 0.8060 - val_loss: 0.6473 - val_acc: 0.7567\n",
            "Epoch 12/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.4505 - acc: 0.8121 - val_loss: 0.5989 - val_acc: 0.7545\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "Epoch 13/25\n",
            "33/33 [==============================] - 28s 838ms/step - loss: 0.4380 - acc: 0.8221 - val_loss: 0.6005 - val_acc: 0.7545\n",
            "Epoch 14/25\n",
            "33/33 [==============================] - 28s 842ms/step - loss: 0.4206 - acc: 0.8264 - val_loss: 0.6708 - val_acc: 0.7522\n",
            "Epoch 15/25\n",
            "33/33 [==============================] - 28s 844ms/step - loss: 0.4271 - acc: 0.8193 - val_loss: 0.6191 - val_acc: 0.7567\n",
            "Epoch 16/25\n",
            "33/33 [==============================] - 28s 842ms/step - loss: 0.4057 - acc: 0.8311 - val_loss: 0.6299 - val_acc: 0.7589\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "Epoch 17/25\n",
            "33/33 [==============================] - 28s 846ms/step - loss: 0.4149 - acc: 0.8259 - val_loss: 0.6272 - val_acc: 0.7589\n",
            "Epoch 18/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.3899 - acc: 0.8340 - val_loss: 0.5569 - val_acc: 0.7991\n",
            "Epoch 19/25\n",
            "33/33 [==============================] - 28s 844ms/step - loss: 0.3959 - acc: 0.8359 - val_loss: 0.6414 - val_acc: 0.7612\n",
            "Epoch 20/25\n",
            "33/33 [==============================] - 28s 841ms/step - loss: 0.3879 - acc: 0.8344 - val_loss: 0.6042 - val_acc: 0.7701\n",
            "Epoch 21/25\n",
            "33/33 [==============================] - 28s 847ms/step - loss: 0.3998 - acc: 0.8354 - val_loss: 0.5785 - val_acc: 0.7656\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "Epoch 22/25\n",
            "33/33 [==============================] - 28s 842ms/step - loss: 0.4089 - acc: 0.8335 - val_loss: 0.6588 - val_acc: 0.7656\n",
            "Epoch 23/25\n",
            "33/33 [==============================] - 28s 842ms/step - loss: 0.3840 - acc: 0.8390 - val_loss: 0.5882 - val_acc: 0.7746\n",
            "Epoch 24/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.3714 - acc: 0.8525 - val_loss: 0.5611 - val_acc: 0.7835\n",
            "Epoch 25/25\n",
            "33/33 [==============================] - 28s 843ms/step - loss: 0.4025 - acc: 0.8378 - val_loss: 0.6978 - val_acc: 0.7522\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z5zL7a0QtUO",
        "outputId": "c135dcee-f644-4609-de96-94b2b5a561c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model2.save(\"2ndModel.h5\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48QeLrMRfBj2",
        "outputId": "5aba5e62-1259-4e8a-99fa-b69286769f11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nLUIY9Wfn4h",
        "outputId": "ad36f647-eb19-4715-be48-f123da25f563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git init"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRtZ8hu1gFww"
      },
      "source": [
        "!git add 0thModel.h5"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXgGgzJvgd83"
      },
      "source": [
        "!git add 1stModel.h5"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibsHrj4AgiR_"
      },
      "source": [
        "!git add 2ndModel.h5"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDeVuXDVgm4F",
        "outputId": "9979d42a-18ef-4f5e-f096-6fb8a55553cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git status"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "\n",
            "No commits yet\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git rm --cached <file>...\" to unstage)\n",
            "\n",
            "\t\u001b[32mnew file:   0thModel.h5\u001b[m\n",
            "\t\u001b[32mnew file:   1stModel.h5\u001b[m\n",
            "\t\u001b[32mnew file:   2ndModel.h5\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31m.config/\u001b[m\n",
            "\t\u001b[31mmedical-image-analysis/\u001b[m\n",
            "\t\u001b[31msample_data/\u001b[m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTpNFzXKhFr_"
      },
      "source": [
        "!git config --global user.email \"hssneha03@gmail.com\"\n",
        "!git config --global user.name \"snehahs03\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp5qDIRMgryd",
        "outputId": "461c188f-c06a-4444-9731-bf6691efef35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git commit -m 'h5 files added of resnet50'"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master (root-commit) febe160] h5 files added of resnet50\n",
            " 3 files changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 0thModel.h5\n",
            " create mode 100644 1stModel.h5\n",
            " create mode 100644 2ndModel.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxOg97Ykg2me",
        "outputId": "301734a9-0087-4cec-f66c-c8a882f60b77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git remote add origin https://github.com/snehahs03/medical-image-analysis.git"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: remote origin already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-FjLouthk5c",
        "outputId": "d0afc8fd-e9a8-420a-fe35-c919f9695e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git push origin master"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7LLhgaQ6xW"
      },
      "source": [
        "**FINE TUNING - 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeqyETEHQ6Ty",
        "outputId": "5476bdb2-124b-40ed-ecf5-4195fec90dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "source": [
        "for layer in pre_trained_model.layers[0:11]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "model4 = Model(pre_trained_model.input, x)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model4.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, \n",
        "                                            min_lr=0.000001, cooldown=2)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 25\n",
        "history3 = model4.fit_generator(train_datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, Y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              validation_steps=(X_val.shape[0] // batch_size),\n",
        "                              callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "33/33 [==============================] - 33s 871ms/step - loss: 0.4964 - acc: 0.8164 - val_loss: 0.7038 - val_acc: 0.7545\n",
            "Epoch 2/25\n",
            "33/33 [==============================] - 28s 841ms/step - loss: 0.4637 - acc: 0.8027 - val_loss: 0.6795 - val_acc: 0.7299\n",
            "Epoch 3/25\n",
            "23/33 [===================>..........] - ETA: 7s - loss: 0.4702 - acc: 0.8106"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-649d264c8953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                               \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                               callbacks=[learning_rate_reduction])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1957\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNNFjoEPQ6Hd"
      },
      "source": [
        "model3.save(\"3rdModel.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRFSRse_RZUQ"
      },
      "source": [
        "**FINE TUNING - 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F56e3nrZTnW9"
      },
      "source": [
        "y = tensorflow.keras.layers.Flatten()(last_output)\n",
        "y = tensorflow.keras.layers.Dense(512, activation='relu')(y)\n",
        "y = tensorflow.keras.layers.Dropout(0.5)(y)\n",
        "y = tensorflow.keras.layers.Dense(3, activation='softmax')(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTJIfhhiRZD1"
      },
      "source": [
        "for layer in pre_trained_model.layers[11:25]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "model5 = Model(pre_trained_model.input, y)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model4.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, \n",
        "                                            min_lr=0.000001, cooldown=2)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 25\n",
        "history4 = model4.fit_generator(train_datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, Y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              validation_steps=(X_val.shape[0] // batch_size),\n",
        "                              callbacks=[learning_rate_reduction])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vQv4ecXRY9F"
      },
      "source": [
        "model3.save(\"4thModel.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTkcONXUPcbg"
      },
      "source": [
        "# Retrieve a list of accuracy results on training and test data\n",
        "# sets for each training epoch\n",
        "acc0 = np.array(history0.history['val_accuracy'])\n",
        "acc1 = np.array(history1.history['val_acc'])\n",
        "acc2 = np.array(history2.history['val_acc'])\n",
        "acc3 = np.array(history3.history['val_acc'])\n",
        "acc4 = np.array(history4.history['val_acc'])\n",
        "\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "loss0 = history0.history['val_loss']\n",
        "loss1 = history1.history['val_loss']\n",
        "loss2 = history2.history['val_loss']\n",
        "loss3 = history2.history['val_loss']\n",
        "loss4 = history3.history['val_loss']\n",
        "\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc0))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc0, label = \"training\")\n",
        "plt.plot(epochs, acc1, label = \"fine_tuning1\")\n",
        "plt.plot(epochs, acc2, label = \"fine_tuning2\")\n",
        "plt.plot(epochs, acc3, label = \"fine_tuning3\")\n",
        "plt.plot(epochs, acc4, label = \"fine_tuning3\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss0, label = \"training\")\n",
        "plt.plot(epochs, loss1, label = \"fine_tuning1\")\n",
        "plt.plot(epochs, loss2, label = \"fine_tuning2\")\n",
        "plt.plot(epochs, loss3, label = \"fine_tuning3\")\n",
        "plt.plot(epochs, loss4, label = \"fine_tuning4\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuUtbb0Xnpi9"
      },
      "source": [
        "loss_test, acc_test = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (acc_test, loss_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICr1N3ETscji"
      },
      "source": [
        "model.save(\"InceptionResNet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STnWw-KCtvVM"
      },
      "source": [
        "# Retrieve a list of accuracy results on training and test data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc, label = \"training\")\n",
        "plt.plot(epochs, val_acc, label = \"validation\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss, label = \"training\")\n",
        "plt.plot(epochs, val_loss, label = \"validation\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e94a28c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "y_pred = model.predict(X_val)\n",
        "# Convert predictions classes to one hot vectors \n",
        "y_pred_classes = np.argmax(y_pred,axis = 1) \n",
        "# Convert validation observations to one hot vectors\n",
        "y_true = np.argmax(Y_val,axis = 1) \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes) \n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yivc4PnFl4RE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}