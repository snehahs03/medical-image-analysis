{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehahs03/medical-image-analysis/blob/main/resnet3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtL75wHma2bt",
        "outputId": "0e743d5d-327e-4a94-abe4-38234ff44359"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HlPTmKabKuU",
        "outputId": "accb1f98-a9f6-4b90-e6ff-0c08bd8380f3"
      },
      "source": [
        "%cd /content/drive/MyDrive/medical-image-analysis"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/medical-image-analysis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb19RMs1-_cu"
      },
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tensorflow.keras import backend as K\n",
        "import gc\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D \n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.preprocessing import image\n",
        "from glob import glob"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2YXrT4J_Mer"
      },
      "source": [
        "def Dataset_loader(DIR, RESIZE, sigmaX=10):\n",
        "    IMG = []\n",
        "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "    for IMAGE_NAME in tqdm(os.listdir(DIR)):\n",
        "        PATH = os.path.join(DIR,IMAGE_NAME)\n",
        "        _, ftype = os.path.splitext(PATH)\n",
        "        if ftype == \".jpg\":\n",
        "            img = read(PATH)\n",
        "           \n",
        "            img = cv2.resize(img, (RESIZE,RESIZE))\n",
        "           \n",
        "            IMG.append(np.array(img))\n",
        "    return IMG"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAoAK-7l_ULL",
        "outputId": "12513e00-6322-4d6f-902f-e406e53b2c60"
      },
      "source": [
        "eczema_train = np.array(Dataset_loader(\"/content/drive/MyDrive/medical-image-analysis/test/Eczema Photos\", 224))\n",
        "melanoma_train = np.array(Dataset_loader(\"/content/drive/MyDrive/medical-image-analysis/train/Melanoma Skin Cancer Nevi and Moles\",224))\n",
        "psoriasis_train = np.array(Dataset_loader(\"/content/drive/MyDrive/medical-image-analysis/train/Psoriasis pictures Lichen Planus and related diseases\",224))\n",
        "eczema_test = np.array(Dataset_loader(\"/content/drive/MyDrive/medical-image-analysis/test/Eczema Photos\",224))\n",
        "melonoma_test = np.array(Dataset_loader(\"/content/drive/MyDrive/medical-image-analysis/test/Melanoma Skin Cancer Nevi and Moles\",224))\n",
        "psoriasis_test = np.array(Dataset_loader(\"/content/drive/MyDrive/medical-image-analysis/test/Psoriasis pictures Lichen Planus and related diseases\", 224))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 309/309 [01:36<00:00,  3.19it/s]\n",
            "100%|██████████| 463/463 [02:22<00:00,  3.26it/s]\n",
            "100%|██████████| 1405/1405 [07:00<00:00,  3.34it/s]\n",
            "100%|██████████| 309/309 [00:02<00:00, 140.66it/s]\n",
            "100%|██████████| 318/318 [01:31<00:00,  3.47it/s]\n",
            "100%|██████████| 352/352 [01:43<00:00,  3.41it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOFq80Gi_XID"
      },
      "source": [
        "#labelling \n",
        "eczema_train_label = np.full(len(eczema_train),0)\n",
        "melonoma_train_label = np.full(len(melanoma_train),1)\n",
        "psoriasis_train_label = np.full(len(psoriasis_train),2)\n",
        "eczema_test_label = np.full(len(eczema_test),0)\n",
        "melonoma_test_label = np.full(len(melonoma_test),1)\n",
        "psoriasis_test_label = np.full(len(psoriasis_test),2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuibS0Ab_lTC"
      },
      "source": [
        "X_train = np.concatenate((eczema_train, melanoma_train, psoriasis_train), axis=0)\n",
        "Y_train = np.concatenate((eczema_train_label, melonoma_train_label, psoriasis_train_label), axis=0)\n",
        "X_test = np.concatenate((eczema_test, melonoma_test, psoriasis_test), axis=0)\n",
        "Y_test = np.concatenate((eczema_test_label, melonoma_test_label, psoriasis_test_label), axis = 0)\n",
        "#print(Y_test.shape)\n",
        "#print(X_test.shape)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q46ALqdo_oS8"
      },
      "source": [
        "s = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_train = X_train[s]\n",
        "Y_train = Y_train[s]\n",
        "\n",
        "s = np.arange(X_test.shape[0])\n",
        "np.random.shuffle(s)\n",
        "#X_test = X_test[s]\n",
        "#Y_test = Y_test[s]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02lI6ES2_rGK"
      },
      "source": [
        "Y_train = to_categorical(Y_train, num_classes= 3)\n",
        "Y_test = to_categorical(Y_test, num_classes= 3)\n",
        "\n",
        "#train and evaluation split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "    X_train, Y_train, \n",
        "    test_size=0.3, \n",
        "    random_state=5\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LI5XNMrgVHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e0899d-f41c-4db6-ee9b-f7d48341f3ae"
      },
      "source": [
        "pre_trained_model = tensorflow.keras.applications.ResNet50(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2LZWem8gAef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425e8b11-badf-457d-8aa0-921e70a62c3d"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "    #print(layer.name)\n",
        "    if hasattr(layer, 'moving_mean') and hasattr(layer, 'moving_variance'):\n",
        "        layer.trainable = True\n",
        "        K.eval(K.update(layer.moving_mean, K.zeros_like(layer.moving_mean)))\n",
        "        K.eval(K.update(layer.moving_variance, K.zeros_like(layer.moving_variance)))\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "print(len(pre_trained_model.layers))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arThh6CiALfL",
        "outputId": "43e37de4-6b0e-4c98-8853-250bbcf06dd2"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('conv5_block3_out')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23NNU55ehETQ"
      },
      "source": [
        "x = tensorflow.keras.layers.Flatten()(last_output)\n",
        "x = tensorflow.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tensorflow.keras.layers.Dropout(0.5)(x)\n",
        "x = tensorflow.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "#Config and compile model\n",
        "\n",
        "model1 = Model(pre_trained_model.input, x)\n",
        "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX5zYiIaAmOL"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=60, width_shift_range=0.2, height_shift_range=0.2,\n",
        "                                   shear_range=0.2, zoom_range=0.2, fill_mode='nearest')\n",
        "\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_datagen.fit(X_val)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyILdlHjAj_k"
      },
      "source": [
        "TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0HfvRrmEy_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0801601-a1b6-4b65-969a-d8fcc55b5406"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 5\n",
        "history0 = model1.fit_generator(train_datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, Y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size), \n",
        "                              validation_steps=(X_val.shape[0] // batch_size))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 57s 887ms/step - loss: 2.0469 - accuracy: 0.6210 - val_loss: 206957314048.0000 - val_accuracy: 0.6562\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 18s 775ms/step - loss: 0.9248 - accuracy: 0.6902 - val_loss: 119471.6250 - val_accuracy: 0.6031\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 18s 769ms/step - loss: 0.6498 - accuracy: 0.7464 - val_loss: 624.1506 - val_accuracy: 0.5688\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 18s 761ms/step - loss: 0.6173 - accuracy: 0.7581 - val_loss: 21.6739 - val_accuracy: 0.5125\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 18s 771ms/step - loss: 0.5762 - accuracy: 0.7745 - val_loss: 2.4939 - val_accuracy: 0.4969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwKQytXZpVoQ"
      },
      "source": [
        "**FINE TUNING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FXRdFeNnVfA",
        "outputId": "63200a69-6a53-4046-8e00-0ccefc84d958"
      },
      "source": [
        "model3 = Model(pre_trained_model.input, x)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTmmbBoxnGNg"
      },
      "source": [
        "for layer in pre_trained_model.layers[:7]:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBrdwZ_7nZ0Y"
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, \n",
        "                                            min_lr=0.000001, cooldown=2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1v1RoX6nhuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f07ed7-fafb-4f0c-fcf5-be051f81773d"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "history2 = model3.fit_generator(train_datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, Y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              validation_steps=(X_val.shape[0] // batch_size),\n",
        "                              callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "23/23 [==============================] - 22s 799ms/step - loss: 0.7333 - acc: 0.7642 - val_loss: 1.9634 - val_acc: 0.6719\n",
            "Epoch 2/30\n",
            "23/23 [==============================] - 18s 773ms/step - loss: 0.6282 - acc: 0.7704 - val_loss: 1.0017 - val_acc: 0.6812\n",
            "Epoch 3/30\n",
            "23/23 [==============================] - 18s 770ms/step - loss: 0.6249 - acc: 0.7738 - val_loss: 0.8633 - val_acc: 0.6469\n",
            "Epoch 4/30\n",
            "23/23 [==============================] - 18s 780ms/step - loss: 0.5546 - acc: 0.7834 - val_loss: 0.5606 - val_acc: 0.7812\n",
            "Epoch 5/30\n",
            "23/23 [==============================] - 18s 786ms/step - loss: 0.5498 - acc: 0.7896 - val_loss: 0.6365 - val_acc: 0.7594\n",
            "Epoch 6/30\n",
            "23/23 [==============================] - 18s 767ms/step - loss: 0.5476 - acc: 0.7985 - val_loss: 0.6191 - val_acc: 0.7688\n",
            "Epoch 7/30\n",
            "23/23 [==============================] - 18s 765ms/step - loss: 0.5044 - acc: 0.8074 - val_loss: 0.5835 - val_acc: 0.7906\n",
            "Epoch 8/30\n",
            "23/23 [==============================] - 18s 763ms/step - loss: 0.4923 - acc: 0.8225 - val_loss: 0.5009 - val_acc: 0.7906\n",
            "Epoch 9/30\n",
            "23/23 [==============================] - 18s 763ms/step - loss: 0.4476 - acc: 0.8252 - val_loss: 0.5945 - val_acc: 0.8125\n",
            "Epoch 10/30\n",
            "23/23 [==============================] - 18s 767ms/step - loss: 0.4203 - acc: 0.8355 - val_loss: 0.5716 - val_acc: 0.7719\n",
            "Epoch 11/30\n",
            "23/23 [==============================] - 18s 763ms/step - loss: 0.4064 - acc: 0.8334 - val_loss: 0.5385 - val_acc: 0.7594\n",
            "Epoch 12/30\n",
            "23/23 [==============================] - 18s 768ms/step - loss: 0.4160 - acc: 0.8369 - val_loss: 0.5568 - val_acc: 0.7875\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "Epoch 13/30\n",
            "23/23 [==============================] - 18s 761ms/step - loss: 0.3814 - acc: 0.8547 - val_loss: 0.5257 - val_acc: 0.8031\n",
            "Epoch 14/30\n",
            "23/23 [==============================] - 18s 765ms/step - loss: 0.3634 - acc: 0.8492 - val_loss: 0.5264 - val_acc: 0.8188\n",
            "Epoch 15/30\n",
            "23/23 [==============================] - 18s 766ms/step - loss: 0.3609 - acc: 0.8725 - val_loss: 0.5589 - val_acc: 0.7937\n",
            "Epoch 16/30\n",
            "23/23 [==============================] - 18s 763ms/step - loss: 0.3368 - acc: 0.8711 - val_loss: 0.5355 - val_acc: 0.7688\n",
            "Epoch 17/30\n",
            "23/23 [==============================] - 18s 773ms/step - loss: 0.3464 - acc: 0.8711 - val_loss: 0.4868 - val_acc: 0.7750\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "Epoch 18/30\n",
            "23/23 [==============================] - 18s 765ms/step - loss: 0.3121 - acc: 0.8794 - val_loss: 0.4773 - val_acc: 0.7875\n",
            "Epoch 19/30\n",
            "23/23 [==============================] - 18s 764ms/step - loss: 0.3060 - acc: 0.8807 - val_loss: 0.5054 - val_acc: 0.7875\n",
            "Epoch 20/30\n",
            "23/23 [==============================] - 18s 771ms/step - loss: 0.2860 - acc: 0.8869 - val_loss: 0.5957 - val_acc: 0.8031\n",
            "Epoch 21/30\n",
            "23/23 [==============================] - 18s 759ms/step - loss: 0.3135 - acc: 0.8753 - val_loss: 0.4835 - val_acc: 0.7875\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "Epoch 22/30\n",
            "23/23 [==============================] - 18s 770ms/step - loss: 0.2751 - acc: 0.8979 - val_loss: 0.4558 - val_acc: 0.8156\n",
            "Epoch 23/30\n",
            "23/23 [==============================] - 18s 760ms/step - loss: 0.2970 - acc: 0.8965 - val_loss: 0.5061 - val_acc: 0.8125\n",
            "Epoch 24/30\n",
            "23/23 [==============================] - 18s 765ms/step - loss: 0.2718 - acc: 0.8862 - val_loss: 0.4743 - val_acc: 0.8250\n",
            "Epoch 25/30\n",
            "23/23 [==============================] - 18s 765ms/step - loss: 0.2803 - acc: 0.8903 - val_loss: 0.5030 - val_acc: 0.8000\n",
            "Epoch 26/30\n",
            "23/23 [==============================] - 18s 763ms/step - loss: 0.2719 - acc: 0.9006 - val_loss: 0.5112 - val_acc: 0.7906\n",
            "Epoch 27/30\n",
            "23/23 [==============================] - 18s 769ms/step - loss: 0.2872 - acc: 0.8869 - val_loss: 0.4907 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "Epoch 28/30\n",
            "23/23 [==============================] - 18s 763ms/step - loss: 0.2717 - acc: 0.8986 - val_loss: 0.4655 - val_acc: 0.8156\n",
            "Epoch 29/30\n",
            "23/23 [==============================] - 18s 763ms/step - loss: 0.2680 - acc: 0.8986 - val_loss: 0.4355 - val_acc: 0.8188\n",
            "Epoch 30/30\n",
            "23/23 [==============================] - 18s 756ms/step - loss: 0.2490 - acc: 0.9061 - val_loss: 0.5990 - val_acc: 0.7937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECNQAcebs0g6"
      },
      "source": [
        "np.save('his2_resnet.npy',history2.history)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfkewlEdlPGq",
        "outputId": "44975cdd-b617-4f2b-834b-c6cc99f1d565"
      },
      "source": [
        "model3.save(\"2ndModel.h5\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuUtbb0Xnpi9",
        "outputId": "637a2ab4-4ea8-4116-d2fc-14a56ffda0d7"
      },
      "source": [
        "loss_test, acc_test = model3.evaluate(X_test, Y_test, verbose=1)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (acc_test, loss_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 4s 110ms/step - loss: 0.4237 - acc: 0.8272\n",
            "Test: accuracy = 0.827198  ;  loss = 0.423693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e94a28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "e7ae3f71-79e7-4482-b34a-5c2a3bff47c8"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix 0f resnet3',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "y_pred = model3.predict(X_test)\n",
        "# Convert predictions classes to one hot vectors \n",
        "y_pred_classes = np.argmax(y_pred,axis = 1) \n",
        "# Convert validation observations to one hot vectors\n",
        "y_true = np.argmax(Y_test,axis = 1) \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes) \n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}